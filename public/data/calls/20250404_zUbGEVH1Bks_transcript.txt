[00:00] **Marc the Shark**: I guess, the payment structure. I think we're going to have a free tier. But of course, the rest of the code is free. So if you want to set up your own Open Web UI, you're more than welcome to do so.

[00:15] **kushti**: All right, and so what are the main use cases for the current indexes? So is it for like intelligence? Like analyzing the blockchain?

[00:33] **Marc the Shark**: Yeah, I'm hoping to create sort of agents that were able to maybe say, hey, set up a grid trading bot for me and then analyze the data for like the last couple of days, look at the grid trading bots and say, hey, okay, we're doing pretty well. Maybe let's update it, put more money into the grid trading bot for a specific pair or be able to spend the boxes itself on say the Spectrum Finance. So be able to say, hey, go ahead and buy a specific pair. Maybe some sort of update recursively, like every hour it checks, hey, should I buy, sell, hold, and sort of do that sort of mechanism. So allow the agents to be able to operate on chain per the prompt.

[01:22] **kushti**: That's interesting. It would be good to get some applications generated by just prompting the LLM.

[01:38] **Marc the Shark**: Absolutely. That's the next step, but we need to consider some initial applications.

[01:45] **kushti**: But, yeah, it would be good to get, I don't know, like a new oracle pool, for example, config for it with just one or two prompts. So, to get data, some API client or scraper for some data, that's usually about just a few lines of code. And getting Oracle Pool config done, so we'll set the number of participants and so on. That's what we are discussing for the upcoming version 2 of USD Oracle Pool. What should be number of participants and so on? But then, in this case, we have quite complicated update procedure from version one to version two. And in case of generating a new pool, it would be good to have LLM generating a config. And then we can do more like generate stable coins, because it's mostly about using a new Oracle and maybe tweaking parameters. Then, yeah, people may do some stable coins.

[03:15] **kushti**: More stable and then some tooling like options which could be nice because originally options were created for raising funds for agriculture industry, for farmers. But, it's quite complicated instrument it was. It used to be so only banksters can do options, and you need to have some big experience and so on to write down a first option. But then, with LLM, maybe it would be possible to avoid intermediaries. So, a farmer can just generate an option and launch it immediately on chain instead of dealing with banksters and paying a lot of money for that.

[04:27] **Marc the Shark**: What's the resource requirements for setting up something like that?

[04:32] **kushti**: So, I think there is some that the base with scenarios. So, what's our parameters? But here, maybe, in case if it's possible to fit a quite big database to a LLM, it could be better than a human in writing options, because after all it's not that... there is nothing magic here, it's not that complicated task for LLM. Shouldn't be complicated, shouldn't be doable.

[05:35] **Marc the Shark**: And they have an MCP. So an MCP server for databases already. So like, for example, there's one for Postgres. And so you'll be able to facilitate, you know, say, hey, what's in this data? Let's just generally analyze it and then just give it sort of those, with the database name, all the APIs keys and things like that, and should be able to kind of parse that out in a lot easier fashion. I'm not sure what database you mentioned, but I would imagine they probably have one for that.

[06:12] **kushti**: All right. How's the mining pool doing? Sigmanauts mining pool.

[06:20] **Marc the Shark**: Yeah, we're doing good. Let's see, I think we're right about 90 GHz at the moment. I'm currently working on updating the web page for us. So kind of, we kind of were thinking, you know, this is sort of like the first sort of look for new miners. And so we really need to have something a little bit more polished for our website. And so I'm working on updating it. We have like the prototype in terms of UI and UX done. So now it's just working on the backend. And so I used lovable.dev to generate the front end and then from there working with Cursor to facilitate the backend integration with the APIs from our mining pool that we have. So hopefully within a couple weeks we'll have that up and running and ready to go.

[07:14] **Marc the Shark**: Yeah, we're just mining away. Going to reach out to a couple other YouTube miners, see if we can get them on the peer-to-peer podcast and talk about mining, because it seems a lot of talk lately. Ergo is the last refuge for GPU miners, and so I'd like to capitalize on that sort of idea. You know, it's a great place to be, great place to mine, especially with demurrage. We handed out over 150 ERGs this last week with demurrage rewards. Then of course, we've got the bonus rewards coming through as well. So definitely we have the incentive there to mine to our pool compared to any other pool on Ergo, just because of the fact, let alone we have demurrage as well as the bonus tokens.

[08:06] **kushti**: All right nice nice so from my side so preparing 6.0 release now syncing with the mainnet and fixing some issues on the way so hard to predict when mainnet ready, 6.0 would be released, so now we're messing with a little bit obscure issue. A bit hard to predict, but anyway, it's close and then we will start working with the mining pools on getting activation, setting activation date and informing mining pools about the upcoming votes for protocol update, soft fork, 6.0 soft fork.

[09:18] **kushti**: Then, yeah, so for sub-blocks, peer-to-peer logic initial version is done, so in a few days we'll invite maybe one or two folks to participate testing devnet now with some peer-to-peer layer so there is need for just like two or three people there to update the nodes constantly because it's still super raw and so on but yeah there is progress there aside of that there is upcoming 5026 not released now with long-awaited feature of Candidate Regeneration so it would allow for faster confirmation of transactions. So with Hardchains transaction we'll get into the next block. And then, a lot of other fixes and small improvements there. So hopefully it will be released next week.

[10:50] **kushti**: Then, yeah, a good report from MewFinance and there are a lot of updates in the ecosystem towards unrolling new releases and so on. Then yeah I personally published a couple of new schemes on the forum. Maybe LLM would be quite useful there as well for launching, for example, off-chain monetary systems for communities. But yeah, we need first to find how to do that manually.

[11:43] **Marc the Shark**: Yeah, it should be standardized in some way and how you set up off-chain bots.

[11:54] **kushti**: Then, yeah, a lot of updates in regards with development and a lot of talks, so a lot of new contributors recently, so a lot of talks about what's that doing so yeah a lot of interesting things check developers chats and so on if you're interested.

[12:37] **Marc the Shark**: So I have a question for you about sub-blocks. How would the mempool work with sub-blocks being really quick confirmation times? Would there be sort of this new idea with the mempool where, you know, because obviously they wouldn't be there that long for the confirmation. So is there going to be like a need to enter mediary between like the mempool and like confirmed or how does that work?

[13:05] **kushti**: So in some regard, yeah, so sub-blocks providing confirmations but with a higher rate of orphans, much higher rate, obviously. You may expect more rollbacks, so mempool would kind of buffer anyway when you are doing from one sub-block to another transactions are getting back to pool when you're applying new transactions but new from a better chain but a sub-block chain but it could be that some transaction old fork would sit in the mempool waiting for newer blocks. So, yeah, it's more the same mechanics but yeah, now, higher speed. So, there would be a need to have bigger memory usage sub-blocks memory on mempool because they are in some sense about more same after blocks so you are putting with a mempool sub-blocks. And yeah, mempool would be smaller now.

[15:02] **Marc the Shark**: Right. Yeah, that's kind of what I was thinking.

[15:12] **kushti**: Because some algorithms are deficient in the mempool, so it would be good for a smaller pool. So I think it could be not that efficient in comparison with having transactions in sub-block.

[15:45] **Marc the Shark**: All right, gotcha. But I would imagine so with sub-blocks, we're probably going to get new APIs to be able to call or are we going to have the same APIs from the node in the index nodes?

[16:01] **kushti**: There will be new APIs and some methods already implemented, but yeah just two or three. So it's a very initial API. So in the first place, the fault would be on peer-to-peer and then on API for extra indices that's still open.

[17:10] **kushti**: So yeah, let me open the questions also. Do we have anything there? Oh, second.

[17:21] **Marc the Shark**: It looks like we have some in the chat.

[17:25] **kushti**: With the global economy looking like it is looking like it's in for a tough time do you think this will hurt or help crypto? I have no idea what do you think? Yeah so about crypto should help Ergo it's contra cyclical. The problem is that currently the Ergo in my opinion kind of trapped so it's considered crypto and crypto is 99 percent useless. It has some pro-cyclical value but yeah mostly more for buying bitcoin and monero using to bypass using bitcoin for him or holding and I think now also monero maybe some there is even Proof-of-Work will tell about some foreign fans now looking for work beyond Bitcoin and so on.

[19:09] **kushti**: Kind of activity with that exact so in TTC so our crypto cards should be in and should help better money in turbulent times so we have only kind of passive digital gold. So Bitcoin and Ergo, was positioned initially as presentations back in September, October 2019 as digital gold with contracts. So digital gold with an ability to create trust. derivative instruments on top of it, then it's possible to do expansion to produce better for the real world. To connect, so, like, all IOUs, so, created, all IOUs created within some T, with chain reserves. But different economic is connected. So that's possible with ergobots. Yeah, the problem is cognition now, I believe. So people are considering that there is crypto is doing something but what exactly I know for the proposition crypto that these days aside of just speculative creation assets some assets so yeah but but it's hopefully now tens of different entities around the globe so let's see it's anything but yeah it's time it's time for Ergo to get recognized.

[22:15] **Marc the Shark**: So we got another question. What sort of applications do you think will benefit from sub-blocks?

[22:28] **kushti**: Exchange, I think like DEX and so on.

[22:38] **Marc the Shark**: Yeah, totally. It's general transactions. You don't have to wait for like three minutes.

[22:45] **kushti**: Yeah maybe on ramp so you don't have it for minutes when you are with this person in the f-rides, for example, you don't need to try it for minutes. Yeah. A forum post on what to do for such deals rather than with sub-blocks. It's also quite fancy. You can meet someone to get a bit exchanged for cash and then you can get ERGs immediately with sub-blocks and not RSBTC but yeah basically it's payton RSBTC from locked UTXO if no proof for bitcoin transfer is printed within certain time frame like six hours for example 12 hours so the worst lock time I've the bitcoin chain out four hours I believe, but often you need to wait for two hours. It's quite often. Bitcoin, blockchain or when you exchange cash for Bitcoin, wait for confirmation. Yeah, it's quite painful.

[24:51] **Marc the Shark**: So everything should be a lot faster from like Rosen to sending TXs, you know, even, I guess our mining pool when we distribute, everything will be a lot, lot faster.

[25:04] **kushti**: Yeah, otherwise I'm here because it seems that there for quite a long time to exclude any security on the blockchain. So it's about Ergo.

[25:23] **Marc the Shark**: There should still be something like speed up though. I mean, just from a TX perspective, like once they're done with the security aspects and like, you know, just from like, I would imagine maybe it's minimal, just from like, I don't really know what goes on behind the scenes, but I would imagine just because you can transact factor faster, at least on the Ergo side, it'll be a little bit faster, maybe not super noticeable.

[25:50] **kushti**: Yeah, let's see. So, yeah, maybe it helps a bit. In regards with mining pools, I'm not sure, it's probably the same. So, I don't know, the Sigmanauts mining pools specifically. But for others, it's usually just like few actions with two inputs and very many outputs linked to mine and they're doing such transactions I don't know like twice a day something like that and then yeah I mean from sub not getting that much so you just transactions to the network and they get into payments would be a lot faster for sure. In a few minutes and yeah, if it's not a few minutes but faster, I mean, it's the same. Most of the menus are not for payments, like every few seconds. Every few minutes even, so they're checking like once a day, so maybe it's more or less the same after all. But yeah for trade and so on it's better and there were some games which now could be revived like one it's by Hayley with some kind of thing it could be revived on some blocks I believe something like that.

[27:46] **Marc the Shark**: Okay. Yeah. I think that, like you said, like, you know, an on-ramp system would be interesting. Like, like Stripe has a payment system where a lot of people have been using that for their vibe coded games and things like that, where they put the payment in there, put your credit cards. It'd be interesting, you know, especially with sub-blocks where you could reduce the settlement time. be able to use Stripe, be able to build something to on-ramp so then people pay in USD and then you can send them ERG or whatever they want, maybe something with Rosen Bridge as well for other specific coins or tokens.

[28:31] **Marc the Shark**: Cool, cool. We have a question. How does one get started with vibe coding for ErgoTree and React? So I guess for React, I would probably suggest using cursor, but of course there's other AI agent coding frameworks that you could use. That's just something I use. You could also just use the native Anthropic Claude, Claude.com. And so basically, and I would even just like, you know, look at the landscape. So Grok is actually really good as well. And so some LLMs are better than others at doing specific tasks. So I would maybe kind of think, play around with those sort of notions. And so sometimes what I like to do is I'll go in one LLM like Claude Sonnet 3.7 and say, hey, I need to write a prompt to do this. So, for example, I wanted to make Sigmanauts mining pool. I took a screenshot of our current dashboards. I was able to say, hey, grab all these metrics, understand what they are, make them into a readme document, and then build some sort of Markdown structure and design of how it works and what we need. And then write this prompt. I then took that prompt and put it into lovable.dev. And then lovable.dev then created and generated the entire UI for me in UX. And so React, if you wanted to make a webpage, you could do that as well. I did the same thing with this airdrop tool that I made for like NFTs and tokens so you can mass distribute that to people. So in short, you can use lovable.dev to maybe stand up some sort of front end. You can then push that to GitHub, pull that into Cursor and then develop the backend. So there's a lot of different ways you can swing with it. And so I would probably suggest sort of come up with a simple project and then kind of try different LLMs and kind of see what works for you and kind of go from there.

[30:31] **Marc the Shark**: In terms of ErgoTree, that is something I think we're kind of still working on. I haven't really been working on that too specifically, but really what you need there is the context. And so as long as you have the specific context, so like for ErgoScript, you can give it GitHub repos that have like legitimate smart contracts. And you could say, hey, this is example code. This is sort of what I want to do. And then again, also maybe you could say these example code, make diagrams out of it so it makes sense and make sure it understands the UTXO model. And this is kind of what we're trying to do with the Ergo MCP. And so the So it gives the context to the LLM. And then from there, when you actually prompt it, and it probably won't be a one shot like, hey, make this contract for like a dead man switch. So if I die, I publish this stuff to the blockchain. You know, probably it's gonna be some fine tuning, some tweaking, but I think it could potentially get you maybe 50 to 70% of the way. And then the rest you can kind of have to test out for yourself. So, but again, I think it's all about playing around and testing it.

[31:44] **Marc the Shark**: I don't know, what are your thoughts? kushti, have you tried Vibe coding at all? Any AI tools have you used?

[31:57] **kushti**: So I've tried to do some core developments using, yeah, Sonnet 3.5 I believe and yeah so it's and yeah I'll try to to do some comps not but tests actually for ChainCash and so all tests, it's working very well. We generated some tests, planned for change with just a goal prompt and it worked immediately. It was a very nice experience. Development, it seems, it's not computable, so quite subtle, but you are spending a lot of time to figure out what's wrong with them. So, yes, it's producing some complicated code. It's looking okay from the first, but then there are some subtle bugs, actually.

[33:25] **kushti**: Yeah, it's definitely kind of an art, you know. Yeah but for tests you know it's working really great so yeah well most of time I think tests now could be saved and actually it's quite a big time saver because all tests also are quite complicated for the load and for the interpreter. And for cache and DEX, all tests are weathered, but length 3 or 4 lines of code per hour tests easily. It could be because, yeah, you need to assemble a transaction according to different concerns and so on, then check, succeed or fail. And then with the help of LLM, you can ask for many hours actually on that. So yeah, that's quite a great tooling for standard coding, standard kinds of coding. Yeah, maybe API. I will try to do my API methods. Yeah, for complicated stuff. Complicated stuff? Yeah, algorithms are heavier. Yeah, it's not that good. But yeah, that's quite expected also.

[35:24] **Marc the Shark**: Yeah, and it's like most tools. Not every tool is a hammer. And so if you treat every tool like it's a hammer, it's bound to break, it's bound to not work. And so knowing when to use AI and when not to use AI is definitely a good skill to have. And then I think relative to the more complex problems, even with ErgoScript, for example, it just doesn't have a lot of the context that it needs. So for example, like Python, You know, it was trained on a lot of Python code within GitHub. There's so much lines on there. Whereas ErgoScript, there's obviously not too much. And so there is a notion to where maybe we need to fine tune a specific model so we can train, say, hey, this is how you make this specific contract. This is how you make this contract. And so that's something else we're also looking at. I think MCPs might be able to get us there before we do that. But if somebody else wants to do that, by all means, send it. We have about 190 ERGs when we're ready to test and generate smart contracts. And so that we're going to pay some auditors. So once we get there, if we can pay some folks to audit them, pay them for their time, and then hopefully the output is sufficient for what we're working with. But only time will tell.

[37:01] **kushti**: Yeah. So, to add more, you have a lot of open so applications, open contracts and so on. So, then, it would be very helpful to LLM to produce ErgoScript LLM. I believe.

[37:23] **Marc the Shark**: Yeah, absolutely. Yeah, definitely. And I think from a fine tuning perspective, you know, it's probably sufficient with the contracts that we have on the chain right now are rather open source. So then that way, you know, it doesn't sort of get super confused. You can really like hone in, so to speak on these specific contracts and how they're written and how they're executed. And so, but but but I guess the problem might be. And so it could maybe overfit. So, for example, if you have like a pinlock contract, it was trained on and then you say, hey, make me another pinlock contract with a little bit more extendedness. It will probably do that really well. But if you try to say, hey, make me write like a a dead man switch, so to speak. It might not know how to do that explicitly. But I think the goal isn't to one-shot these smart contracts. That's not my goal. My goal is to make it 50% to 75% easier to write the smart contracts. And so if I can get 50% to 75% to say the first draft of the smart contract, that works for me because then I can finesse it or whatever it needs to do. Ask kushti, do you write? Hey, what's going on here? So that's sort of my goal. It sort of speeds up the smart contract timeline of development. And that would be pretty powerful, I think. So then more folks helps democratize in some sense, sort of these coding abilities, maybe. And maybe not everybody should be making smart contracts, I suppose. There's some sort of notion of security and safety, I guess, with that sort of respect. Would be cool.

[39:07] **Marc the Shark**: So somebody else says, let's see. I know we don't do wash trading or other nonsense like some other chains, but Ergo and associated dApps have been stress tested at any point. So I'm not sure. Have we done any sort of stress test? I mean, I know, for example, we've people have tried to stress test, you know, fitting the most amount within a given box relative to a given transaction. So like, you know, sending one input to like 10,000 outputs, I suppose.

[40:03] **kushti**: How do you stress test the blockchain, I guess? Stress testing events, but yeah, so for kind of synthetic stress testing, I'm not aware of. There were a lot of discussions and I think for our sub-blocks, yeah, there would be needed to do testnet stress testing. But first, we need to get more realistic testnet apologies, so we'll invite more folks to the Testnet because, it doesn't make sense to do stress testing. So that's the problem with many, actually, papers and so on, white papers claiming some high TPS when you realize what they're doing they just have few nodes or even many nodes over the same data center and then yeah it doesn't make sense because it's not looking like a real peer-to-peer network. So first we need to get a little bigger testing network, but that's doable. And then yeah, we can do stress testing.

[41:29] **Marc the Shark**: Yeah, that'd be cool to do, you know, especially to, to be able to, I mean, I think you made a good point. The test net topology, like say for example, well, if I wanted to test out one input to 10,000 outputs, like where would I even get all the 10,000 addresses? I mean, I guess you generate them, you know, how would you do that?

[41:50] **kushti**: Yeah, so for main nets there were some stress tests for many outputs and one actually broken many notes because of some back in light clients actually but those light clients then broke full clients and so and then yeah many pools we're struggling yeah basically not we are restarting out of memory, but that was like four years ago, so like 2021, it was some Aneta airdrop. And yeah, after that, the network survived somehow, but yeah, many nodes were under pressure. And Yeah, after that, we did some fixes. And, after that, I can't remember. So there were many events like airdrops and yeah, there was some events when a few thousands of transactions was sent to the network at one shot, but yeah, everything was sitting smoothly by the network as well.

[43:45] **Marc the Shark**: Yeah. Yeah. In terms of test net, I would love to set up a Sigmanauts mining pool test net, and then that would be kind of interesting. Easier to set up maybe, I don't know.

[43:59] **Marc the Shark**: Let's see, so we got a couple questions on sub-blocks. So will sub-blocks affect scalability? You know, what if one billion people are using Ergo and then can sub-blocks TXs be chained within a single block? Yeah, so can sub-blocks TXs be changed within a single block?

[44:28] **kushti**: Yeah, but so transactions can be chained in a single sub-block. And yes, single block also, because yeah, a block would be just a sequence of sub-blocks mostly for most of transactions. But, yeah, about billions of people. So still there is need for layer 2s and not just because of TPS. So I think that would be quite natural design. So today I tweeted diagram of how our Hawala system works, conceptually. So it's about, you know, some global network and then local segments are connected to Hawala, Hawala, so local exchange booth. So, yeah, I believe it should be the same here when you have some local segment, which is mostly exchanging. with people, actors, agents, mostly exchanging within this segment. So they need for some off-chain solution. There is no need for global consensus. When you buy coffee from some local supplier, I mean, why? Why do you need for global consensus? Why some? Why some miner in Argentina and some Ergo enthusiast in Vietnam India or China should know about that even so such economic activity Should be localized I believe ledger wise also and then yeah I know for global consensus, we need to have some, I don't know, events which are really needed there on the global level.

[46:49] **Marc the Shark**: Yeah, it makes a lot of sense. I haven't really thought about it in terms of the global consensus sort of versus like local. That's a good way to put that because I mean totally like why you know from a local you know I am buying coffee like why does the global Ergo chain kind of care about that you know what I mean it's like yeah just do it off chain and then you know have that sort of segment do that that makes a lot of sense.

[47:15] **kushti**: Yeah I mean maybe there is need for some settlements and clearing between different local segments and so on and then yeah there is need for global consensus. There is need for global consensus maybe in regards with some global events and so on but yeah for For most of activities, like real world activities, I believe there is no need for global consensus, so he immediately did a global consensus. So there is no need to write that you bought a cup of coffee from some local supplier.

[48:02] **Marc the Shark**: Yeah, absolutely.

[48:06] **kushti**: Yeah, that doesn't make sense economically even, not technically even.

[48:15] **Marc the Shark**: Yeah, I mean, even in the United States, we've got the federal government, but then we also have our local governments and then our city governments. So it makes sense. The federal government doesn't really care what we do, so to speak, on certain local perspectives. So it makes sense to, as we scale up, we continue to offload specific aspects to these other layers.

[48:45] **kushti**: All right. So one more question.

[48:49] **Marc the Shark**: Looks like, let's see, how can both Ergo and Cardano collaborate with each other from a transaction happen on the chain, on the respective chain? So I guess we're kind of doing that with Rosen Bridge.

[49:10] **kushti**: Yeah, but what I thought about actually is can we have multi-chain Hydra, for example. And as Cardano is supporting the elliptic curve used in Ergo, secp256k1, I guess that's doable in some form. I need to recheck the Hydra paper. But that would be quite interesting when you may have some off-chain high-speed rails basically for financial and not just financial transactions, powered from both the chains at the same time. So, it would be interesting. Maybe it could be collateralized from both the chains. So, outcomes may happen on both the chains, so some on Ergo side, some on Cardano side. The other question is for some like real-world use cases, not to have it just as a quite, I don't know, exciting toy. But yeah, it sounds interesting at least. Yeah, let's see. Yeah, I think, in regards with such stuff, there are a lot of technical opportunities between Ergo Cardano and other UTXO blockchains.

[51:08] **Marc the Shark**: Okay, awesome. Awesome.

[51:14] **Marc the Shark**: One last quick question, I guess. When is the next P2P podcast? Yeah, we need to sit down and record that. Me and Tim have just been busy kind of working on a few things. So hopefully within this next week, we'll get something out to you guys.

[51:27] **kushti**: All right. So do you have a guest?

[51:31] **Marc the Shark**: We don't. We'll either just do it with us or you're welcome to come on and we'd be happy to chat with you.

[51:37] **kushti**: Yeah, so we can do one. Let me think. So yeah, the best time would be around wait or April 19th, Saturday, or Friday before 18th. So something like that, yeah, would be quite good.

[52:02] **Marc the Shark**: Okay, cool. Yeah. I'll reach out to Tim and then we'll start a group chat. But what can we talk about? I can maybe prepare some cool stuff in advance.

[52:11] **kushti**: So I can check the Hydra paper and we can have a talk about different off-chain systems. So recently I've published that off-chain design, a new one, it was a forum post on Monday. So the idea is to have a layer 2 where participants may create IOUs, money off-chain and then have on-chain redemption for them so it's a kind of reverse of ordinary off-chain cash schemes such as Fedimint or Cashew for Bitcoin where you have on-chain reserves and mint not against them so always redeemable. notes so so so here yeah you are going opposite so it's not always redeemable maybe but you have more money off chain which also does make sense i believe in real world applications but then yeah i'm also interested in those schemes like Cashew Fedimint, Skridcache, Lightning Network a little bit, but to me it seems limited. Then Hydra and so on, so like state channel kind of systems. And more so I think there could be maybe hundreds of different designs. It would be good to think how to make them interoperable. There are also, for example, there is ARK on Bitcoin. I'm studying a little bit, but it's hard to say and it looks quite messy. I even asked in the group recently, do they have any white paper and security analysis and it seems not really so just massive writings and some codes you need to figure out how security is by your own and sometimes some issues found there so but still could be considered as well and as I said there could be hundreds of different off-chain designs with properties maybe it's worth to somehow classify them and yeah maybe for auto generation of chain systems so after okay. Lighting network failure, which is what we are witnessing. Yeah, I think even Bitcoin Maxis would be quite open to more off-chain solutions. They're open even now, so it seems ARK, for example, is getting there from my observations after visiting some there are two events. I mean so, yeah, we may discuss off-chain schemes, but we may discuss okay, cool.

[56:00] **Marc the Shark**: Yeah, I mean, I think the ground is super fertile, and so we'll be excited to explore that here with you. All right, keep an eye on them. Yeah, absolutely. And let's see. I think one last question. I know I said the last. time. But someone said, how do you incentivize testnet mining? I just had this idea. And so we could, if we had a Sigmanauts testnet mining pool, we could see if your address or you could prove somehow you're mining to our pool and testnet and mainnet. And then maybe we could give you like bonus tokens or something like that for mining on both of our pools, testnet and mainnet. So that's maybe a way to incentivize that. But any case, we can explore that.

[56:44] **kushti**: I actually had an idea to build first trustless bridge between Ergo mainnet and Ergo testnet and then we can bring the testnet ERG to the mainnet and then yeah it's up to people how to incentivize so maybe some people may put ERG along with testnet ERG into a liquidity pool and so on interesting to see possible experiments. That would be interesting.

[57:25] **Marc the Shark**: Yeah. Yeah, absolutely. It's fun to experiment.

[57:29] **kushti**: And yeah, by the way, I have some question, if you mind, the last maybe. So what's Sigmanauts mining pool doing with the tokens they got from storage rent? Any plans or any actions already aside of that PHP?

[57:56] **Marc the Shark**: Yeah, for sure. So we launched PHP, let's see, probably a few months ago, and then CannonQ locked that up into a liquidity pool with most of it. And then so we're distributing some of it to the miners. We're distributing, let's see, I think it's on Spectrum DEX. So that's like out live in the ecosystem repurposed. We have a couple tokens kind of here and there. So we have like a Carbidge one, an Oracle, test one and two, Felter Snatch. So nothing really, I guess, of note, but we'd be happy, I suppose, if somebody was interested. sell them on MewFinance, maybe bundle them all up, get it to the mining pool. And then we distribute that into the miners. but, the PHP token is the only token where we've got the totality of all of the supply for a given token. And then that's where we're like, Hey, let's go ahead and launch something. But, yeah, it's been actually really great so far. I think, I think the liquidity pool is like 20,000 or something like that for a PHP. So that's, that's kind of neat to see. Interesting. Nice. and some other random tokens I'm looking at now.

[59:15] **kushti**: Yeah, but it seems a lot of tokens going to the pool. So you're collecting all the tokens first. And then decide what to do. I like to burn.

[59:33] **Marc the Shark**: Yeah, well, I guess token-wise, we haven't really set any rules or stuff, whether do we want to burn it. Right now, it's just sitting in our wallet aside from PHP. And then the ERG is distributed based upon the block and the miner's payout of that, which is equivalent to their participation. So for example, if you got 50% of the reward, we're going to wait that one for 50% and then the next block is say, you know, 40%. And then we kind of average that with the rest of everybody else. And then once a week on Tuesdays, we airdrop that to everybody. And then the pool will start taking 1% of that.

[60:16] **Marc the Shark**: All right. Yeah, good. Okay, so we're rocking and rolling. And so yeah, we got 150 last week, we probably have probably got over maybe like 500 or since we have started, probably more than that.

[60:32] **kushti**: Nice. So it's a nice incentive for our pool for sure.

[60:37] **kushti**: And yeah, and I guess already maybe hundreds of kilobytes of garbage cleaned out from the UTXO set.

[60:54] **Marc the Shark**: Yeah, definitely. It's pretty neat to see. It's cool to see. Relative to the Sigmanauts Monocle update, we're debating right now. Do we open source it? Do we create the steps? I think a lot of the miners are under the impression, this is what makes us marketable. Most of everything's on is open source, but we're not going to explicitly give you guys the steps, I suppose, at least for the time being. So we're going to continue to build what they call the moat between us and other pools to kind of make us more marketable and bring more miners in. And then once I think we are sufficient there, we'll then distribute that or make the steps, I guess, more transparent. But feel free, if you disagree with us and you're in the mining pool, definitely reach out. We are going to put it to a vote. And then from there, just reach out if you disagree, you don't like that. But this isn't necessarily just my opinion, this is other people's opinions within the pool. It's definitely a collective thought, although I think qx() is very wanting to release it to the general community. but again, it's all open source. So if somebody really wanted to try to do it, they could. So it's not like any of it's closed source.

[62:29] **kushti**: So yeah, let's see. How's it going?

[62:40] **kushti**: All right. So let's wrap up with this.

[62:44] **Marc the Shark**: All right. Yeah, that sounds good. Well, it's a nice chat with you, kushti. Thanks for the questions, everybody.

[62:53] **kushti**: Yeah. Good to see, the format and the team always changing. And yeah, always building at the same time. So, yeah, have a good day, Marc, and have a good day, guys. See you, everybody.